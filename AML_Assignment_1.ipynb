{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMy2P6lTT6J2/5Ru33fF1EU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aamirburma/ANN-CNN-Performance-Benchmark/blob/main/AML_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. **Setup & Dataset Preparation (Task 1)**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Objective\n",
        "- Load the MNIST, Fashion MNIST, and CIFAR-10 datasets.\n",
        "- Ensure they are correctly formatted for ANN and CNN models.\n",
        "- Normalize the data for better convergence during training.\n",
        "\n",
        "## Concepts:\n",
        "- MNIST (Modified National Institute of Standards and Technology) dataset:\n",
        "  - 70,000 grayscale images of **handwritten digits (0–9)**.\n",
        "  - Image size: **28×28 pixels**.\n",
        "  - Single-channel (grayscale).\n",
        "- Fashion MNIST:\n",
        "\n",
        "  - 70,000 grayscale images of clothing items (e.g., shirts, shoes).\n",
        "  - Also 28×28 pixels, single-channel.\n",
        "- CIFAR-10:\n",
        "\n",
        "  - 60,000 **RGB images** (color).\n",
        "  - Image size: **32×32** pixels.\n",
        "  - 10 categories: Airplane, Car, Bird, Cat, Deer, Dog, Frog, Horse, Ship,Truck.\n",
        "\n",
        "## Implementation Steps\n",
        "1. **Load datasets using TensorFlow/Keras.**\n",
        "2. **Normalize pixel values** by dividing by 255.0 (for better model performance).\n",
        "3. **Reshape data** if necessary for CNNs."
      ],
      "metadata": {
        "id": "w4gsRqAUh0AM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Iq8PA52hijt",
        "outputId": "b18b75e0-92dc-4d08-bccf-3b92e004add8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
            "MNIST: (60000, 28, 28, 1), (60000,)\n",
            "Fashion MNIST: (60000, 28, 28, 1), (60000,)\n",
            "CIFAR-10: (50000, 32, 32, 3), (50000, 1)\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train_mnist, y_train_mnist), (x_test_mnist, y_test_mnist) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Load Fashion MNIST dataset\n",
        "(x_train_fmnist, y_train_fmnist), (x_test_fmnist, y_test_fmnist) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train_cifar, y_train_cifar), (x_test_cifar, y_test_cifar) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize data (scale values between 0 and 1)\n",
        "x_train_mnist, x_test_mnist = x_train_mnist / 255.0, x_test_mnist / 255.0\n",
        "x_train_fmnist, x_test_fmnist = x_train_fmnist / 255.0, x_test_fmnist / 255.0\n",
        "x_train_cifar, x_test_cifar = x_train_cifar / 255.0, x_test_cifar / 255.0\n",
        "\n",
        "# Reshape MNIST & Fashion MNIST (CNNs expect 3D inputs)\n",
        "x_train_mnist = x_train_mnist.reshape(-1, 28, 28, 1)\n",
        "x_test_mnist  = x_test_mnist.reshape(-1, 28, 28, 1)\n",
        "\n",
        "x_train_fmnist = x_train_fmnist.reshape(-1, 28, 28, 1)\n",
        "x_test_fmnist  = x_test_fmnist.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# CIFAR-10 is already in (32, 32, 3) shape, no need to reshape\n",
        "\n",
        "# Print shapes for verification\n",
        "print(f\"MNIST: {x_train_mnist.shape}, {y_train_mnist.shape}\")\n",
        "print(f\"Fashion MNIST: {x_train_fmnist.shape}, {y_train_fmnist.shape}\")\n",
        "print(f\"CIFAR-10: {x_train_cifar.shape}, {y_train_cifar.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Expected Outcome\n",
        "- The datasets are loaded correctly.\n",
        "- The images are normalized (values between 0 and 1).\n",
        "- MNIST and Fashion MNIST are reshaped into (28, 28, 1) for CNN compatibility.\n",
        "\n",
        "\n",
        "---\n",
        "# **Task 2: ANN Implementation**\n",
        "## Objective:\n",
        "- Train an Artificial Neural Network (ANN) on each dataset.\n",
        "- Use different activation functions: ReLU, Sigmoid, Tanh.\n",
        "- Evaluate accuracy and loss.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Concepts:\n",
        "- Artificial Neural Networks (ANNs):\n",
        "  - Flatten layer: Converts image matrices into a 1D vector.\n",
        "  - Dense (Fully Connected) layer: Processes features.\n",
        "  - Activation functions:\n",
        "    - ReLU (Rectified Linear Unit): Helps prevent vanishing gradients.\n",
        "    - Sigmoid: Converts values into range (0,1) but suffers from vanishing gradients.\n",
        "    - Tanh: Scales between (-1,1) but may lead to slow convergence.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Implementation Steps\n",
        "1. Define an ANN model with one hidden layer.\n",
        "2. Train the model with different activation functions.\n",
        "3. Evaluate loss & accuracy for each activation function."
      ],
      "metadata": {
        "id": "CjjDACPplyQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define ANN model\n",
        "def build_ann_model(input_shape, num_classes, activation='relu'):\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Flatten(input_shape=input_shape),  # Flatten input\n",
        "        keras.layers.Dense(128, activation=activation),\n",
        "        keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Function to train & evaluate ANN\n",
        "def train_and_evaluate_ann(model, x_train, y_train, x_test, y_test, epochs=5):\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train, epochs=epochs, validation_split=0.1, verbose=1)\n",
        "    return model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# Experiment with different activation functions\n",
        "activations = ['relu', 'sigmoid', 'tanh']\n",
        "results_ann = []\n",
        "\n",
        "for act in activations:\n",
        "    print(f\"Training ANN with {act} activation\")\n",
        "    ann_model = build_ann_model((28,28,1), 10, activation=act)\n",
        "    loss, acc = train_and_evaluate_ann(ann_model, x_train_mnist, y_train_mnist, x_test_mnist, y_test_mnist)\n",
        "    results_ann.append((act, loss, acc))\n",
        "\n",
        "# Display results\n",
        "for act, loss, acc in results_ann:\n",
        "    print(f\"Activation: {act}, Loss: {loss:.4f}, Accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrwERpYMihSa",
        "outputId": "cc467bf1-b130-4b5b-c3ac-986ec00628f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ANN with relu activation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8711 - loss: 0.4612 - val_accuracy: 0.9633 - val_loss: 0.1327\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9622 - loss: 0.1313 - val_accuracy: 0.9742 - val_loss: 0.0923\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9748 - loss: 0.0846 - val_accuracy: 0.9762 - val_loss: 0.0813\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.0587 - val_accuracy: 0.9775 - val_loss: 0.0809\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.0458 - val_accuracy: 0.9793 - val_loss: 0.0746\n",
            "Training ANN with sigmoid activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8269 - loss: 0.6883 - val_accuracy: 0.9475 - val_loss: 0.1965\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9355 - loss: 0.2244 - val_accuracy: 0.9592 - val_loss: 0.1479\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9551 - loss: 0.1588 - val_accuracy: 0.9670 - val_loss: 0.1177\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9651 - loss: 0.1229 - val_accuracy: 0.9702 - val_loss: 0.1029\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9713 - loss: 0.1010 - val_accuracy: 0.9737 - val_loss: 0.0919\n",
            "Training ANN with tanh activation\n",
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8706 - loss: 0.4560 - val_accuracy: 0.9595 - val_loss: 0.1535\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9530 - loss: 0.1619 - val_accuracy: 0.9700 - val_loss: 0.1070\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9710 - loss: 0.1014 - val_accuracy: 0.9755 - val_loss: 0.0877\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9803 - loss: 0.0713 - val_accuracy: 0.9763 - val_loss: 0.0820\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9849 - loss: 0.0545 - val_accuracy: 0.9725 - val_loss: 0.0820\n",
            "Activation: relu, Loss: 0.0761, Accuracy: 0.9758\n",
            "Activation: sigmoid, Loss: 0.1025, Accuracy: 0.9699\n",
            "Activation: tanh, Loss: 0.0818, Accuracy: 0.9757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Expected Outcome\n",
        "- The ANN trains successfully with different activation functions.\n",
        "- Comparison table of loss & accuracy:\n",
        "\n",
        "| Activation | MNIST Accuracy | Loss |\n",
        "|----------|----------|----------|\n",
        "| ReLU |\t97%\t| 0.08 |\n",
        "| Sigmoid |\t94%\t| 0.13 |\n",
        "| Tanh |\t95%\t| 0.12 |\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **Task 3: CNN Implementation**\n",
        "\n",
        "## Objective:\n",
        "- Train a Convolutional Neural Network (CNN) for image classification.\n",
        "- Test different padding methods and strides.\n",
        "- Compare accuracy & loss.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Concepts:\n",
        "- CNN Layers:\n",
        "  - Conv2D: Extracts features using convolutional filters.\n",
        "  - MaxPooling2D: Downsamples feature maps.\n",
        "  - Dense (Fully Connected): Processes extracted features.\n",
        "- Padding:\n",
        "  - <code>same:</code> Maintains image size.\n",
        "  - <code>valid:</code> Shrinks image.\n",
        "- Strides:\n",
        "  - <code>stride=1:</code> Small movements, high resolution.\n",
        "  - <code>stride=2:</code> Faster computation, lower resolution.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# **Implementation Steps**\n",
        "\n",
        "1. Build a CNN model with configurable padding & stride.\n",
        "2. Train & evaluate for different configurations."
      ],
      "metadata": {
        "id": "XQ0fToBttxyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_cnn_model(input_shape, num_classes, padding='same', stride=1):\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Conv2D(32, (3,3), strides=stride, padding=padding, activation='relu', input_shape=input_shape),\n",
        "        keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "        keras.layers.Conv2D(64, (3,3), strides=stride, padding=padding, activation='relu'),\n",
        "        keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Train CNN\n",
        "cnn_model = build_cnn_model((28,28,1), 10, padding='same', stride=1)\n",
        "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "cnn_model.fit(x_train_mnist, y_train_mnist, epochs=5, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQgDwzuKi4fy",
        "outputId": "3f7f14ff-35d1-49c7-d660-c94f4fdc379c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 43ms/step - accuracy: 0.9092 - loss: 0.2903 - val_accuracy: 0.9828 - val_loss: 0.0547\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 42ms/step - accuracy: 0.9851 - loss: 0.0454 - val_accuracy: 0.9882 - val_loss: 0.0409\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 43ms/step - accuracy: 0.9907 - loss: 0.0279 - val_accuracy: 0.9920 - val_loss: 0.0316\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 42ms/step - accuracy: 0.9942 - loss: 0.0187 - val_accuracy: 0.9858 - val_loss: 0.0471\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 41ms/step - accuracy: 0.9946 - loss: 0.0163 - val_accuracy: 0.9927 - val_loss: 0.0312\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a1c6097bd10>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Expected Outcome\n",
        "- CNN achieves 98–99% accuracy on MNIST.\n",
        "- <code>same</code> padding provides better accuracy than valid padding.\n"
      ],
      "metadata": {
        "id": "HCCtNKzKxCwu"
      }
    }
  ]
}